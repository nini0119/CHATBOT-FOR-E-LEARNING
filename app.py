# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R4wmc0VFqmUf2RSYi2eNOVOD6KBYA5Qi
"""

import streamlit as st
import pandas as pd
import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA, LLMChain
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.documents import Document

# R√©cup√©ration s√©curis√©e de la cl√© API
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

class StreamlitChatbot:
    def __init__(self):
        if 'initialized' not in st.session_state:
            st.session_state.initialized = False
            st.session_state.messages = []

        if not st.session_state.initialized:
            self._initialize_system()
            st.session_state.initialized = True

    def _initialize_system(self):
        """Initialize the system configuration"""
        try:
            # Initialisation du mod√®le
            self.model = ChatOpenAI(
                temperature=0.7,
                model_name="gpt-3.5-turbo"
            )

            # Initialisation des embeddings
            self.embeddings = OpenAIEmbeddings()

            # Chargement des donn√©es
            # Pour le d√©ploiement, assurez-vous que le chemin est correct
            try:
                self.videos_robotics = pd.read_csv("final_videos_robotics (2).csv")
            except FileNotFoundError as e:
                st.error(f"Erreur de chargement du fichier CSV: {str(e)}")
                return

            # Le reste du code reste identique...

# Le reste de votre code reste le m√™me...

            # Initialisation des embeddings
            self.embeddings = OpenAIEmbeddings()

            # Chargement des donn√©es
            try:
                self.videos_robotics = pd.read_csv("final_videos_robotics (2).csv")
            except FileNotFoundError as e:
                st.error(f"Erreur de chargement du fichier CSV: {str(e)}")
                return

            # Pr√©paration des documents
            self.docs = self._prepare_documents(self.videos_robotics)

            # Cr√©ation du vectorstore
            self.vectorstore = self._create_vectorstore(self.docs)

            # Configuration des cha√Ænes
            self.setup_chains()

            st.success("‚úÖ Syst√®me initialis√© avec succ√®s!")

        except Exception as e:
            st.error(f"‚ùå Erreur d'initialisation: {str(e)}")

    def setup_chains(self):
        """Configure les cha√Ænes n√©cessaires"""
        # Configuration de la cha√Æne RAG
        retriever = self.vectorstore.as_retriever(search_kwargs={"k": 2})

        system_prompt = """
        Answer the question based on the provided context. Be concise.
        Context: {context}
        Question: {question}
        """

        prompt = ChatPromptTemplate.from_template(system_prompt)

        self.rag_chain = RetrievalQA.from_chain_type(
            llm=self.model,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={
                "prompt": prompt,
            }
        )

        # Configuration de la cha√Æne de quiz
        quiz_prompt = PromptTemplate.from_template("""
        Based on the following video content, create 5 multiple-choice questions in English.
        Make the questions focused and specific to the video content.

        Video Content: {content}

        Format EXACTLY as follows:

        Q1: [Question]
        A) [Option A]
        B) [Option B]
        C) [Option C]
        D) [Option D]
        Correct Answer: [Letter]

        [Continue for all 5 questions]
        """)

        self.quiz_chain = LLMChain(llm=self.model, prompt=quiz_prompt)

    def _prepare_documents(self, videos_robotics, max_tokens=1000):
        docs = []
        for _, video in videos_robotics.iterrows():
            try:
                if pd.notna(video["transcript_text"]):
                    transcript = video["transcript_text"][:max_tokens]
                    docs.append(Document(
                        page_content=transcript,
                        metadata={"video_id": video["video_id"], "title": video["title"]}
                    ))
            except KeyError as e:
                st.error(f"Erreur de cl√© dans la vid√©o: {e}")
        return docs

    def _create_vectorstore(self, docs):
        texts = [doc.page_content for doc in docs]
        metadatas = [doc.metadata for doc in docs]
        return FAISS.from_texts(
            texts=texts,
            embedding=self.embeddings,
            metadatas=metadatas
        )

    def _generate_quiz(self, video_title):
        """G√©n√®re un quiz bas√© sur le titre de la vid√©o"""
        matching_videos = self.videos_robotics[
            self.videos_robotics['title'].str.contains(video_title, case=False, na=False)
        ]

        if matching_videos.empty:
            return "‚ùå No video found with this title. Please try another title."

        video = matching_videos.iloc[0]

        try:
            response = self.quiz_chain.run(content=video['transcript_text'][:2000])
            return response
        except Exception as e:
            return f"Error generating quiz: {str(e)}"

    def run(self):
        """Lance l'interface Streamlit"""
        st.title("ü§ñ Assistant Robotique")

        # Sidebar pour le mode quiz
        with st.sidebar:
            st.title("Options")
            mode = st.radio("Mode", ["Chat", "Quiz"])

        if mode == "Chat":
            # Interface de chat
            query = st.text_input("Posez votre question:", key="query_input")

            if query:
                try:
                    response = self.rag_chain({"query": query})

                    # Ajouter les messages √† l'historique
                    st.session_state.messages.append({"role": "user", "content": query})
                    st.session_state.messages.append({"role": "assistant", "content": response['result']})

                    # Afficher l'historique des messages
                    for message in st.session_state.messages:
                        if message["role"] == "user":
                            st.write(f"üë§ Vous: {message['content']}")
                        else:
                            st.write(f"ü§ñ Assistant: {message['content']}")

                    # Afficher la source
                    if response.get("source_documents"):
                        doc = response["source_documents"][0]
                        st.info(f"üìö Source: Vid√©o {doc.metadata['video_id']}, "
                               f"Titre: {doc.metadata['title']}")

                except Exception as e:
                    st.error(f"‚ùå Une erreur s'est produite: {str(e)}")

        else:  # Mode Quiz
            video_title = st.text_input("Entrez le titre de la vid√©o pour g√©n√©rer un quiz:")
            if video_title:
                quiz = self._generate_quiz(video_title)
                st.markdown(f"## Quiz pour '{video_title}':")
                st.write(quiz)

def main():
    chatbot = StreamlitChatbot()
    chatbot.run()

if __name__ == "__main__":
    main()